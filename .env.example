# =============================================================================
# LLM Provider Configuration
# Choose ONE provider: OpenAI OR Azure OpenAI
# =============================================================================

# -----------------------------------------------------------------------------
# Option 1: OpenAI (https://platform.openai.com/)
# -----------------------------------------------------------------------------
OPENAI_API_KEY=your-openai-api-key-here

# Optional: Override default model (default: gpt-4)
# OPENAI_MODEL=gpt-3.5-turbo

# -----------------------------------------------------------------------------
# Option 2: Azure OpenAI (https://azure.microsoft.com/en-us/products/ai-services/openai-service)
# -----------------------------------------------------------------------------
# If you set AZURE_OPENAI_ENDPOINT, Azure OpenAI will be used automatically
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment-name
# AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Note: For Azure OpenAI, you still need to set OPENAI_API_KEY (Azure uses it as the API key)
# OPENAI_API_KEY=your-azure-openai-api-key

# =============================================================================
# Optional Configuration
# =============================================================================

# LLM Temperature (0.0 - 2.0, default: 0.7)
# OPENAI_TEMPERATURE=0.7

# Max tokens for LLM response (default: 2000)
# OPENAI_MAX_TOKENS=2000

# Target mutation score (0-100, default: 80)
# TARGET_MUTATION_SCORE=80

# Maximum feedback loop iterations (default: 5)
# MAX_ITERATIONS=5

# Log level (debug, info, warn, error, default: info)
# LOG_LEVEL=info
